---
title: "Unknown Warming: A joy division inspired plot of Temperature Anomalies"
description: >
  visualization of the temperature anomalies in the form of a Joy Division plot.
page-layout: full
author: 
  - name: 
      given: "Dimitri"
      family: "Masson"
    orcid: "0000-0002-7072-3146" 
    email: "d.masson@estia.fr" 
    idhal: "dimitri-masson"
  - name:
      given: "Yann"
      family: "Girard"
citation:
  id: masson2025_UnknownWarming
  citation-key: masson2025_UnknownWarming
  type: post-weblog
  container-title: >
    dhmmasson.github.io
format:
  html:
    # code-fold: true
    code-summary: "Show the code"
toc: false
---


My friend Yann showed me [a graph](https://www.bbc.com/news/science-environment-67861954) he wanted to replicate, where temperature anomalies were plotted by frequency rather than chronologically, resembling a Joy Division plot (Inspired by the album cover of Unknown Pleasures by Joy Division), the graph is created by counting the number of days each anomaly occurs per year and offsetting the resulting curve for each year. To enhance its appearance, I apply a Gaussian blur to smooth the values.

You can play with the parameters to see how the plot changes. The opacity, the scale of the years, the smooth factor, the color, and the option to start the plot from the bottom or to display only the anomalies.

Below are some technical details on how the data is processed and the plot is generated.
:::{.aside}
```{ojs}
//| echo: false
//| panel: sidebar
viewof opacity = Inputs.range([0,1], {step : 0.1, value: 0.9, label: "Opacity"})
viewof yearOffset = Inputs.range([1,8], {step : 1, value: 2, label: "Y Scale"})
viewof smoothFactor = Inputs.range([0,4], {step : 1, value: 3, label: "Smooth Factor"})
viewof fromBottom = Inputs.toggle( {label: "anomaly only", value: true})
viewof color = Inputs.color( {label: "Color", value: "black"})
```
:::


::: {.panel-tabset}
## Plot
```{ojs}
//| echo: false
//| fig-cap: "Joy Division Plot of Temperature Anomalies"
//| fig-attr: "Source: ERA5"
//| fig-attr-url: "https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview"

// Plot using Plot.plot a area chart for each year
chart = Plot.plot({
  marks: [
    Plot.areaY(
        joyData, 
        { x: "anomaly"
        , y1: fromBottom ? 0 : "reference"
        , y2: "height"
        , z: "year"
        , axisY: null
        , fillOpacity: opacity
        , stroke: "white"
        , fill: color  }),

    Plot.axisY(Array(2025-1940).fill(1).map((e,i)=>(i+1)*yearOffset), {
      label: "Year",
      grid: true,
      text: Array(2025-1940).fill(1).map((e,i)=>(""+(2024-i))),
      domain: [maxYear, d3.min(data, d => d.year)]
    }),
    Plot.axisX({
      label: "Temperature Anomaly",
      interval: 0.5
    }),
    // showZero? Plot.ruleX([0], {stroke: "red", strokeOpacity: 0.5}):null,
  ],
  x: {label: "Temperature Anomaly"},
  y: {label: "year"},
  
  width: 800,
  height: 1200,
  padding: 0.1,
  fill: "black",
  title: "Joy Division Plot of Temperature Anomalies",
})
```

:::{.aside}
```{ojs}
//| echo: false
DOM.download(() => serialize(chart.children[1]), undefined, "Download the SVG")
```
:::

## table
```{ojs}
//| echo: false
temp = t => Math.round(t * 100) / 100 +"Â°C";
bidimensionalTable = joyData.reduce( (anomalies, d) => {
  
  if (d.year in anomalies) {
    anomalies[d.year][ temp( d.anomaly) ] =d.count
  } else {
    anomalies[d.year] = {year: d.year} 
    anomalies[d.year][temp( d.anomaly) ] = d.count
  }
  return anomalies
}, []).filter( d => d.year >= 1940)
Inputs.table(bidimensionalTable)
```

:::

## Parsing the data

We start by downloading the data from the copernicus website ( [ERA5](https://cds.climate.copernicus.eu/cdsapp#!/dataset/reanalysis-era5-single-levels?tab=overview) ). 
One of the tricky thing is that the CSV files contains comments lines (starting with #). D3 doesn't handle that by default and we need to remove before parsing the data.

```{ojs}

// Load the CSV file
data = FileAttachment("./era5_daily_series_2t_global.csv").text().then(processCSV);

// Function to preprocess and parse the CSV
function processCSV(content) {
  // Remove comment lines (lines starting with #) // <1>
  const lines = content.split("\n");
  const filteredLines = lines.filter(line => !line.trim().startsWith("#")); 
  const csvContent = filteredLines.join("\n");

  // Parse the CSV content
  return d3.csvParse(csvContent, d3.autoType).map( 
    d => {
        const year = d.date.getFullYear() // <2>
        const janFirst = new Date(year, 0, 1)
        const dayOfYear = Math.floor( (d.date - janFirst) / (1000 * 60 * 60 * 24) ) + 1 // <3>
        return { year
               , day: dayOfYear 
               , anomaly: d["ano_91-20"]
               , corrected : Math.floor( 100 * (d["ano_91-20"] + correction({year, day: dayOfYear})) )/100 }
    } 
  )
}

// Display the parsed data
data
```
1. Filter out the comment lines from the CSV content
2. Anomaly will be grouped by year
3. For anomaly correction we need the day of the year

## Data correction

Applying the formula to correct the temperature anomalies from https://parisagreementtemperatureindex.com/copernicus-1850-1900-baseline-daily-gmst/

```{ojs}

isLeapYear = year => !(year % 4)  // <1> 

correction = ({year, day}) => {
    const days = isLeapYear(year) ? 366 : 365
    const correction = 0.88 + 0.05 * Math.sin((2*3.14159 * (day - 0.5)) / days) // <2>
                            + 0.07 * Math.cos((2*3.14159 * (day - 0.5)) / days) 
    return correction
}
correctionData = d3.timeDay
  .range(new Date(2024, 0, 1, 12), new Date(2025, 0, 1), 1)
  .map( (e,i)=> (
    { date : e
    , year: 2024
    , day: i + 1 
    , correction: correction({year: 2024, day: i + 1})
    }
  )) 

// Line plot of the correction by day of the year
Plot.plot({
  marks: [
    Plot.line(correctionData, { x: "date", y: "correction", stroke: "black" }),
    Plot.ruleY([.88], {stroke: "red", strokeOpacity: 0.5})
  ],
  x: {label: "Day of the year"},
  y: {label: "Correction"},
  width: 800,
  height: 400,
  padding: 0.1,
  title: "Correction of the temperature anomalies"
})
```
1. Checking if the year is a leap year, straight forward calculation between 1940 and 2024
2. Formula 2 from the website


### Grouping 
```{ojs}
maxYear = d3.max(data, d => d.year)

offset = 0.1 
minAnomaly = d3.min(data, d => d.corrected) - offset
maxAnomaly = d3.max(data, d => d.corrected) + offset
length = (maxAnomaly - minAnomaly) * 100
indexF = (x) => Math.round((x - minAnomaly) * 100) // <2> 
indexF_1 = (x) => (x / 100) + minAnomaly 

kernels = [ // <4>
      [1],
      [2, 1],
      [6, 4, 1],
      [20, 15, 6, 1],
      [70, 56, 28, 8, 1],
    ];
joyData =  {

  // Count the number of anomalies for each year // <1>
  let anomalies = data.reduce((anomalies, d) => {
    if (d.year in anomalies) {
      anomalies[d.year][indexF(d.corrected)] += 1;
    } else {
      anomalies[d.year] = Array(length).fill(0);
      anomalies[d.year][indexF(d.corrected)] = 1;
    }
    return anomalies;
  }, {});

  //  Gaussian Blur smoothing 
  let joyData = [];
  for (let year in anomalies) { 
    const kernel = kernels[smoothFactor];
    for (let i = 0; i < length; i++) {
      let result = 0;
      let weight = 0;
      for (let j = 1 - kernel.length; j < kernel.length; j++) {
        if (i + j >= 0 && i + j < length) {
          const absJ = Math.abs(j);
          result += anomalies[year][i + j] * kernel[absJ]; // <3>
          weight += kernel[absJ];
        }
      }
      joyData.push({ 
        year: year,
        anomaly: indexF_1(i), 
        count: result / weight,
        height: result / weight + (maxYear - year) * yearOffset, // <5>
        reference: (maxYear - year) * yearOffset,
      });
    }
  }
  return joyData.filter((d) => d.year != 2025);
}

joyData
```
1. The Graph is produce by counting the number of anomalies for each year.
2. The anomalies are discretized into 0.1 intervals 
3. to apply a gaussian blur
4. From one of 5 kernels for gaussian blur of size 1, 2, 3, 4 and 5.
5. The height of the area chart is calculated from the count and offset by year to produce the Joy Division effect




```{ojs}
//| echo: false
serialize = {
  const xmlns = "http://www.w3.org/2000/xmlns/";
  const xlinkns = "http://www.w3.org/1999/xlink";
  const svgns = "http://www.w3.org/2000/svg";
  return function serialize(svg) {
    svg = svg.cloneNode(true);
    const fragment = window.location.href + "#";
    const walker = document.createTreeWalker(svg, NodeFilter.SHOW_ELEMENT);
    while (walker.nextNode()) {
      for (const attr of walker.currentNode.attributes) {
        if (attr.value.includes(fragment)) {
          attr.value = attr.value.replace(fragment, "#");
        }
      }
    }
    svg.setAttributeNS(xmlns, "xmlns", svgns);
    svg.setAttributeNS(xmlns, "xmlns:xlink", xlinkns);
    const serializer = new window.XMLSerializer;
    const string = serializer.serializeToString(svg);
    return new Blob([string], {type: "image/svg+xml"});
  };
}
```